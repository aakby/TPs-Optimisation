{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> TP-Projet d'optimisation numérique </h1>\n",
    "<h1> Année 2020-2021 - 2e année département Sciences du Numérique </h1>\n",
    "<h1> Amine AKBY </h1>\n",
    "<h1> Anas TITAH </h1>    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de Newton\n",
    "## Implémentation \n",
    "\n",
    "1. Coder l’algorithme de Newton local tel que décrit dans la section *Algorithme de Newton* (fichier `Algorithme_De_Newton.jl`)\n",
    "\n",
    "2. Tester l’algorithme sur les fonctions $f_{1}$ , $f_{2}$ avec les points initiaux $x_{011}$ , $x_{012}$ (pour $f_{1}$ ) et $x_{021}$ , $x_{022}$ , $x_{023}$ (pour $f_{2}$ ) donnés en Annexe A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267948966\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 2\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial -1.0707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = -1.5707963267948966\n",
      "  * f(xsol) = -1.0\n",
      "  * nb_iters = 3\n",
      "  * flag = 2\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f0 au point initial 1.5707963267948966:\u001b[22m\u001b[39m\n",
      "  * xsol = 1.5707963267948966\n",
      "  * f(xsol) = 1.0\n",
      "  * nb_iters = 0\n",
      "  * flag = 2\n",
      "  * sol_exacte : -1.5707963267948966\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f1 au point initial [1, 0, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f1 au point initial [10.0, 3.0, -2.2]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 1\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f2 au point initial [-1.2, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 6\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Newton appliqué à f2 au point initial [10, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 5\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "SingularException(2)",
     "output_type": "error",
     "traceback": [
      "SingularException(2)",
      "",
      "Stacktrace:",
      " [1] checknonsingular at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\factorization.jl:19 [inlined]",
      " [2] checknonsingular at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\factorization.jl:21 [inlined]",
      " [3] lu!(::Array{Float64,2}, ::Val{true}; check::Bool) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\lu.jl:85",
      " [4] #lu#136 at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\lu.jl:273 [inlined]",
      " [5] lu at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\lu.jl:272 [inlined] (repeats 2 times)",
      " [6] \\(::Array{Float64,2}, ::Array{Float64,1}) at D:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\LinearAlgebra\\src\\generic.jl:1116",
      " [7] Algorithme_De_Newton(::typeof(f), ::typeof(gradf), ::typeof(hessf), ::Array{Float64,1}, ::Array{Any,1}) at C:\\Users\\user\\Documents\\2SN\\Optimisation\\TPs\\Optinum\\src\\Algorithme_De_Newton.jl:55",
      " [8] top-level scope at In[1]:75",
      " [9] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#using Pkg; Pkg.add(\"LinearAlgebra\"); Pkg.add(\"Markdown\")\n",
    "# using Documenter\n",
    "using LinearAlgebra\n",
    "using Markdown                             # Pour que les docstrings en début des fonctions ne posent\n",
    "                                           # pas de soucis. Ces docstrings sont utiles pour générer \n",
    "                                           # la documentation sous GitHub\n",
    "include(\"Algorithme_De_Newton.jl\")\n",
    "\n",
    "# Affichage les sorties de l'algorithme des Régions de confiance\n",
    "function my_afficher_resultats(algo,nom_fct,point_init,xmin,fxmin,flag,sol_exacte,nbiters)\n",
    "\tprintln(\"-------------------------------------------------------------------------\")\n",
    "\tprintstyled(\"Résultats de : \",algo, \" appliqué à \",nom_fct, \" au point initial \", point_init, \":\\n\",bold=true,color=:blue)\n",
    "\tprintln(\"  * xsol = \",xmin)\n",
    "\tprintln(\"  * f(xsol) = \",fxmin)\n",
    "\tprintln(\"  * nb_iters = \",nbiters)\n",
    "\tprintln(\"  * flag = \",flag)\n",
    "\tprintln(\"  * sol_exacte : \", sol_exacte)\n",
    "end\n",
    "\n",
    "# Fonction f0\n",
    "# -----------\n",
    "f0(x) =  sin(x)\n",
    "# le gradient de la fonction f0\n",
    "grad_f0(x) = cos(x)\n",
    "# la hessienne de la fonction f0\n",
    "hess_f0(x) = -sin(x)\n",
    "sol_exacte = -pi/2\n",
    "options = []\n",
    "\n",
    "x0 = sol_exacte\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = -pi/2+0.5\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x0 = pi/2\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f0,grad_f0,hess_f0,x0,options)\n",
    "my_afficher_resultats(\"Newton\",\"f0\",x0,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "# Vos tests (f1 et f2)\n",
    "options = []\n",
    "\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) =  2*(x[1]+x[2]+x[3]-3)^2 +(x[1]-x[2])^2 + (x[2]-x[3])^2\n",
    "# le gradient de la fonction f1\n",
    "gradf1(x) = [4(x[1]+x[2]+x[3]-3)+2(x[1]-x[2]);4(x[1]+x[2]+x[3]-3)-2(x[1]-x[2])+2(x[2]-x[3]);4(x[1]+x[2]+x[3]-3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f1\n",
    "hessf1(x) = [6 2 4; 2 8 2; 4 2 6]\n",
    "sol_exacte = [1;1;1]\n",
    "options = []\n",
    "\n",
    "x011 = [1;0;0]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f1,gradf1,hessf1,x011,options)\n",
    "my_afficher_resultats(\"Newton\",\"f1\",x011,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "x012 = [10;3;-2.2]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f1,gradf1,hessf1,x012,options)\n",
    "my_afficher_resultats(\"Newton\",\"f1\",x012,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "########################################################\n",
    "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
    "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
    "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
    "x021 = [-1.2; 1]\n",
    "x022 = [10 ; 0]\n",
    "x023 = [0 ; 1/200 + 1/10^12]\n",
    "options = []\n",
    "sol_exacte = [1; 1]\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x021,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x021,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x022,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x022,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Algorithme_De_Newton(f,gradf,hessf,x023,options)\n",
    "my_afficher_resultats(\"Newton\",\"f2\",x023,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation \n",
    "\n",
    "Justifier\n",
    "\n",
    "1. les résultats obtenus pour l'exemple $f_0$ ci-dessus;\n",
    "\n",
    "2. que l’algorithme implémenté converge en une itération pour $f_{1}$;\n",
    "\n",
    "3. que l’algorithme puisse ne pas converger pour $f_{2}$ avec certains points initiaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Pour la fonction f0 :\n",
    "    Au point -pi/2 : La solution est le point initial -pi/2, ce qui fait que l'algorithme converge en 0 itération.\n",
    "    Au point -pi/2+0.5 : L'algorithme converge en 3 itérations.\n",
    "    Au point pi/2 : L'algorithme converge en 0 itération même si pi/2 n'est pas une solution du problème. En effet, La méthode de Newton ne peut pas distinguer entre un point minimun, maximun.\n",
    "    \n",
    "2- Pour tout x appartient à $R^3$, on a : $hessf1(x)\\times([1,1,1]-x) + gradf1(x) = 0$. Donc, quelque soit le point de départ, on converge toujours en une itération.\n",
    "\n",
    "3- Pour le point $[0; 1/200 + 1/10^{12}]$, la fonction f2 ne converge pas avec l'algorithme. Après certaines itérations, la méthode est appliquée en utilisant une inversion de la matrice Hessienne mal conditionnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régions de confiance avec pas de cauchy \n",
    "\n",
    "## Implémentation \n",
    "\n",
    "1. Coder l'algorithme du pas de Cauchy d’un sous-problème de\n",
    "régions de confiance (fichier `Pas_De_Cauchy.jl`). Tester sur les quadratiques proposées en Annexe B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Pas de cauchy : Quadratique 1 : ([0, 0], 0)\n",
      "Pas de cauchy : Quadratique 2 : ([-0.9230769230769234, -0.30769230769230776], 1)\n",
      "Pas de cauchy : Quadratique 3 : ([5.000000000000001, -2.5000000000000004], -1)\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "include(\"Pas_De_Cauchy.jl\")\n",
    "\n",
    "println(\"-------------------------------------------------------------------------\")\n",
    "println(\"Pas de cauchy : Quadratique 1 : \",Pas_De_Cauchy([0,0],[7 0;0 2] ,1))\n",
    "println(\"Pas de cauchy : Quadratique 2 : \",Pas_De_Cauchy([6,2],[7 0;0 2] ,1))\n",
    "println(\"Pas de cauchy : Quadratique 3 : \",Pas_De_Cauchy([-2,1],[-2 0;0 10] ,1))\n",
    "println(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Coder l'algorithme de régions de confiance (fichier `Regions_De_Confiance.jl`). Tester sur les problèmes de l’Annexe A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-PAS-CAUCHY appliqué à f1 au point initial [1, 0, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0000558873349883, 0.999992420017735, 0.9999289527004819]\n",
      "  * f(xsol) = 9.090411079109608e-9\n",
      "  * nb_iters = 25\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-PAS-CAUCHY appliqué à f1 au point initial [10.0, 3.0, -2.2]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.000052883196468, 0.999995984440483, 0.9999390911896339]\n",
      "  * f(xsol) = 6.764290139243766e-9\n",
      "  * nb_iters = 24\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-PAS-CAUCHY appliqué à f2 au point initial [-1.2, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9945890985557811, 0.9891826711696939]\n",
      "  * f(xsol) = 2.9339377270175686e-5\n",
      "  * nb_iters = 1000\n",
      "  * flag = 3\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-PAS-CAUCHY appliqué à f2 au point initial [10, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9996723179994089, 0.9993433946497942]\n",
      "  * f(xsol) = 1.07557399293696e-7\n",
      "  * nb_iters = 16\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-PAS-CAUCHY appliqué à f2 au point initial [0.0, 0.0050000000010000005]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9777608100454512, 0.9560198672090239]\n",
      "  * f(xsol) = 0.0004945829134589271\n",
      "  * nb_iters = 1000\n",
      "  * flag = 3\n",
      "  * sol_exacte : [1, 1]\n"
     ]
    }
   ],
   "source": [
    "include(\"Regions_De_Confiance.jl\")\n",
    "include(\"Pas_De_Cauchy.jl\")\n",
    "\n",
    "# Vos tests\n",
    "options = []\n",
    "\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) =  2*(x[1]+x[2]+x[3] - 3)^2 +(x[1]-x[2])^2 + (x[2]-x[3])^2\n",
    "# le gradient de la fonction f1\n",
    "gradf1(x) = [4*(x[1]+x[2]+x[3] - 3)+2*(x[1]-x[2]);4*(x[1]+x[2]+x[3] - 3)-2*(x[1]-x[2])+2*(x[2]-x[3]);4*(x[1]+x[2]+x[3] - 3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f1\n",
    "hessf1(x) = [6 2 4;2 8 2; 4 2 6]\n",
    "\n",
    "x011 = [1; 0; 0]\n",
    "x012 = [10; 3; -2.2]\n",
    "sol_exacte = [1; 1; 1]\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"cauchy\",f1,gradf1,hessf1,x011,options)\n",
    "my_afficher_resultats(\"RDC-PAS-CAUCHY\",\"f1\",x011,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"cauchy\",f1,gradf1,hessf1,x012,options)\n",
    "my_afficher_resultats(\"RDC-PAS-CAUCHY\",\"f1\",x012,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "\n",
    "########################################################\n",
    "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
    "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
    "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
    "x021 = [-1.2; 1]\n",
    "x022 = [10 ; 0]\n",
    "x023 = [0 ; 1/200 + 1/10^12]\n",
    "options = []\n",
    "sol_exacte = [1; 1]\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"cauchy\",f,gradf,hessf,x021,options)\n",
    "my_afficher_resultats(\"RDC-PAS-CAUCHY\",\"f2\",x021,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"cauchy\",f,gradf,hessf,x022,options)\n",
    "my_afficher_resultats(\"RDC-PAS-CAUCHY\",\"f2\",x022,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"cauchy\",f,gradf,hessf,x023,options)\n",
    "my_afficher_resultats(\"RDC-PAS-CAUCHY\",\"f2\",x023,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas de cauchy dans le cas f2 avec x023 :([0.049999999984399995, -0.024999999997199998], 1)\n",
      "Pas de cauchy dans le cas f2 avec x022 :([-3.3306452532199136, 0.1665247690463886], -1)\n"
     ]
    }
   ],
   "source": [
    "println(\"Pas de cauchy dans le cas f2 avec x023 :\",Pas_De_Cauchy(gradf(x023),hessf(x023) ,1)) \n",
    "# Avec x023, on converge avec un peu près 2809 iterations.\n",
    "\n",
    "\n",
    "println(\"Pas de cauchy dans le cas f2 avec x022 :\",Pas_De_Cauchy(gradf(x022),hessf(x022) ,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation \n",
    "\n",
    "1. Quelle relation lie la fonction test $f_1$ et son modèle de Taylor à l’ordre 2 ? Comparer alors les performances de Newton et RC-Pas de Cauchy sur cette fonction.\n",
    "\n",
    "2. Le rayon initial de la région de confiance est un paramètre important dans l’analyse\n",
    "de la performance de l’algorithme. Sur quel(s) autre(s) paramètre(s) peut-on jouer\n",
    "pour essayer d’améliorer cette performance ? Étudier l’influence d’au moins deux de\n",
    "ces paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses\n",
    "\n",
    "1-  L'algorithme de Newton est plus performant que l'algorithme de RC-Pas de Cauchhy. En effet, l'algorithme de Newton converge en une itération alors que l'algorithme de RC-Pas de Cauchy converge en 24-25 itérations.\n",
    "\n",
    "2- On doit bien choisir la tolérance absolue, car si on prend une tolérance absolue trop grande, on aura une petite précision et un petit nombre d'itération, et si on prend une tolérance absolue trop petite, on aura une grande précision et un grand nombre d'itération.\n",
    "On doit bien choisir les valeurs initiaux de eta1 et etat2, car si on prend une très grande pour etat1 et une très petite valeur pour etat2, la région de confiance ne se met plus à jour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régions de confiance avec gradient conjugué tronqué\n",
    "\n",
    "## Implémentation \n",
    "\n",
    "1. Implémenter l’algorithme du Gradient Conjugué Tronqué, en se basant sur le cours (fichier `Gradient_Conjugue_Tronque.jl`).\n",
    "On validera les résultats sur les fonctions de l’Annexe C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Gradient Conjugue tronque : Quadratique 1 : [0.0, 0.0]\n",
      "Gradient Conjugue tronque : Quadratique 2 : [1.1782448197996298, -1.6160876042514951]\n",
      "Gradient Conjugue tronque : Quadratique 3 : [-0.5, 0.0]\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vos tests\n",
    "# Question 1\n",
    "include(\"Gradient_Conjugue_Tronque.jl\")\n",
    "\n",
    "println(\"-------------------------------------------------------------------------\")\n",
    "println(\"Gradient Conjugue tronque : Quadratique 1 : \",Gradient_Conjugue_Tronque([0 ,0],[-2 0;0 10] ,[]))\n",
    "println(\"Gradient Conjugue tronque : Quadratique 2 : \",Gradient_Conjugue_Tronque([2 ,3],[4 6;6 5] ,[]))\n",
    "println(\"Gradient Conjugue tronque : Quadratique 3 : \",Gradient_Conjugue_Tronque([2 ,0],[4 0;0 -15] ,[]))\n",
    "println(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Intégrer finalement l’algorithme du Gradient Conjugué Tronqué dans le code de\n",
    "régions de confiance, et appliquer ce code pour résoudre les exemples proposés en\n",
    "Annexe A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-GCT appliqué à f1 au point initial [1, 0, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9999999999999999, 0.9999999999999999, 0.9999999999999999]\n",
      "  * f(xsol) = 3.944304526105059e-31\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-GCT appliqué à f1 au point initial [10.0, 3.0, -2.2]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-GCT appliqué à f2 au point initial [-1.2, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 0.9999999999999999]\n",
      "  * f(xsol) = 1.232595164407831e-30\n",
      "  * nb_iters = 7\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-GCT appliqué à f2 au point initial [10, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0000000117111625, 1.0000000223109624]\n",
      "  * f(xsol) = 2.6066404951583316e-16\n",
      "  * nb_iters = 20\n",
      "  * flag = 2\n",
      "  * sol_exacte : [1, 1]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : RDC-GCT appliqué à f2 au point initial [0.0, 0.0050000000010000005]:\u001b[22m\u001b[39m\n",
      "  * xsol = [1.0, 1.0]\n",
      "  * f(xsol) = 0.0\n",
      "  * nb_iters = 8\n",
      "  * flag = 0\n",
      "  * sol_exacte : [1, 1]\n"
     ]
    }
   ],
   "source": [
    "include(\"Regions_De_Confiance.jl\")\n",
    "\n",
    "# Vos tests\n",
    "options = []\n",
    "\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) =  2*(x[1]+x[2]+x[3] - 3)^2 +(x[1]-x[2])^2 + (x[2]-x[3])^2\n",
    "# le gradient de la fonction f1\n",
    "gradf1(x) = [4*(x[1]+x[2]+x[3] - 3)+2*(x[1]-x[2]);4*(x[1]+x[2]+x[3] - 3)-2*(x[1]-x[2])+2*(x[2]-x[3]);4*(x[1]+x[2]+x[3] - 3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f1\n",
    "hessf1(x) = [6 2 4;2 8 2; 4 2 6]\n",
    "\n",
    "x011 = [1; 0; 0]\n",
    "x012 = [10; 3; -2.2]\n",
    "sol_exacte = [1; 1; 1]\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"gct\",f1,gradf1,hessf1,x011,options)\n",
    "my_afficher_resultats(\"RDC-GCT\",\"f1\",x011,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"gct\",f1,gradf1,hessf1,x012,options)\n",
    "my_afficher_resultats(\"RDC-GCT\",\"f1\",x012,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "\n",
    "########################################################\n",
    "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
    "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
    "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
    "x021 = [-1.2; 1]\n",
    "x022 = [10 ; 0]\n",
    "x023 = [0 ; 1/200 + 1/10^12]\n",
    "options = []\n",
    "sol_exacte = [1; 1]\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"gct\",f,gradf,hessf,x021,options)\n",
    "my_afficher_resultats(\"RDC-GCT\",\"f2\",x021,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"gct\",f,gradf,hessf,x022,options)\n",
    "my_afficher_resultats(\"RDC-GCT\",\"f2\",x022,xmin,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "xmin,f_min,flag,nb_iters = Regions_De_Confiance(\"gct\",f,gradf,hessf,x023,options)\n",
    "my_afficher_resultats(\"RDC-GCT\",\"f2\",x023,xmin,f_min,flag,sol_exacte,nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation  \n",
    "\n",
    "1. Comparer la décroissance obtenue avec celle du pas de Cauchy, en retournant, dans\n",
    "un premier temps le dernier itéré admissible à courbure positive (c’est à dire, que si\n",
    "l’une ou l’autre des deux conditions (b) ou (d) sont rencontrées dans l’algorithme 3,\n",
    "alors on ne calcule pas ``σ_{j}`` et on retourne le dernier itéré ``s_{j}`` directement).\n",
    "\n",
    "2. Comparer la décroissance obtenue avec celle du pas de Cauchy, en imposant la sortie\n",
    "dans l’algorithme 3 au bout d’une itération seulement. Que remarquez vous ?\n",
    "\n",
    "3. Comparer la décroissance obtenue avec celle du pas de Cauchy dans le cas général.\n",
    "\n",
    "4. Quels sont les avantages et inconvénients des deux approches ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses\n",
    "\n",
    "1- Pour ce cas, l'algorithme RDC-GCT est plus performant que l'algorithme RDC avec pas de cauchy, car il converge en moins d'itérations pour tous les points.\n",
    "\n",
    "2- Pour le cas d'une seule itération, l'algorithme RDC-GCT converge pour le premier point de la première fonction et ne converge pas pour les autres cas, tandis que l'algorithme avec pas de cauchy converge.\n",
    "\n",
    "3- Dans le cas général, l'algorithme RDC-GCT est meilleur que l'algorithme RDC-Pas de Cauchy.\n",
    "\n",
    "4- Lalgorithme de RDC avec Pas de Cauchy considère une direction gk ce qui fait que le pas donnée n'est pas le plus optimal.\n",
    "\n",
    "La méthode du gradient conjugué a donc une convergence superlinéaire, qui peut être mise à mal par un mauvais conditionnement de la matrice. Elle reste toutefois meilleure que les algorithmes à direction de plus forte pente comme l'algorithme de Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangien augmenté\n",
    "\n",
    "## Implémentation\n",
    "1.Choisir des critères d’arrêt pour la convergence de l'algorithme.\n",
    "\n",
    "2.Implémenter l'algorithme du lagrangien augmenté, en utilisant les différentes méthodes\n",
    "qui ont été vues en première partie pour la résolution de la suite de problémes sans\n",
    "contraintes (fichier `Lagrangien_Augmente.jl`)\n",
    " \n",
    "3.Tester les différentes variantes sur les problèmes en Annexe D.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = Newton appliqué à f1 au point initial [0, 1, 1]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.5000000001207722, 1.249999999939614, 0.5000000001207721]\n",
      "  * f(xsol) = 2.2499999989130512\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [0.5, 1.25, 0.5]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = GCT appliqué à f1 au point initial [0, 1, 1]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.5000000001207722, 1.2499999999396139, 0.5000000001207722]\n",
      "  * f(xsol) = 2.249999998913051\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [0.5, 1.25, 0.5]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = Newton appliqué à f1 au point initial [0.5, 1.25, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.5000000001207722, 1.249999999939614, 0.5000000001207721]\n",
      "  * f(xsol) = 2.2499999989130512\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [0.5, 1.25, 0.5]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = GCT appliqué à f1 au point initial [0.5, 1.25, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.5000000001207722, 1.2499999999396139, 0.5000000001207722]\n",
      "  * f(xsol) = 2.249999998913051\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : [0.5, 1.25, 0.5]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = Newton appliqué à f2 au point initial [1, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.0068516285821773925, -1.2247257295950154]\n",
      "  * f(xsol) = 150.99315408560696\n",
      "  * nb_iters = 6\n",
      "  * flag = 0\n",
      "  * sol_exacte : Any[]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = GCT appliqué à f2 au point initial [1, 0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9072339558672259, 0.8227554478848268]\n",
      "  * f(xsol) = 0.00861565152172191\n",
      "  * nb_iters = 2\n",
      "  * flag = 0\n",
      "  * sol_exacte : Any[]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = Newton appliqué à f2 au point initial [0.8660254037844386, 0.8660254037844386]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9072339605060928, 0.8227554563054669]\n",
      "  * f(xsol) = 0.008615650660836534\n",
      "  * nb_iters = 3\n",
      "  * flag = 0\n",
      "  * sol_exacte : Any[]\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = GCT appliqué à f2 au point initial [0.8660254037844386, 0.8660254037844386]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.9072339605060928, 0.8227554563054669]\n",
      "  * f(xsol) = 0.008615650660836534\n",
      "  * nb_iters = 3\n",
      "  * flag = 0\n",
      "  * sol_exacte : Any[]\n"
     ]
    }
   ],
   "source": [
    "# Vos tests\n",
    "include(\"Lagrangien_Augmente.jl\")\n",
    "\n",
    "using LinearAlgebra\n",
    "\n",
    "################# f1 ############################\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) =  2*(x[1]+x[2]+x[3] - 3)^2 +(x[1]-x[2])^2 + (x[2]-x[3])^2\n",
    "# le gradient de la fonction f1\n",
    "gradf1(x) = [4*(x[1]+x[2]+x[3] - 3)+2*(x[1]-x[2]);4*(x[1]+x[2]+x[3] - 3)-2*(x[1]-x[2])+2*(x[2]-x[3]);4*(x[1]+x[2]+x[3] - 3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f1\n",
    "hessf1(x) = [6 2 4;2 8 2; 4 2 6]\n",
    "contrainte1(x) = x[1]+x[3]-1\n",
    "grad_contrainte1(x) = [1;0;1]\n",
    "hess_contrainte1(x) = [0 0 0; 0 0 0; 0 0 0] \n",
    "options = []\n",
    "x0 = [0;1;1]\n",
    "x1 = [0.5;1.25;1]\n",
    "sol_exacte = [0.5, 1.25, 0.5]\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"newton\",f1,contrainte1,gradf1,hessf1,grad_contrainte1,hess_contrainte1,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = Newton\",\"f1\",x0,x_min,f_min,flag,sol_exacte,nb_iters)\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"gct\",f1,contrainte1,gradf1,hessf1,grad_contrainte1,hess_contrainte1,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = GCT\",\"f1\",x0,x_min,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"newton\",f1,contrainte1,gradf1,hessf1,grad_contrainte1,hess_contrainte1,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = Newton\",\"f1\",x1,x_min,f_min,flag,sol_exacte,nb_iters)\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"gct\",f1,contrainte1,gradf1,hessf1,grad_contrainte1,hess_contrainte1,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = GCT\",\"f1\",x1,x_min,f_min,flag,sol_exacte,nb_iters)\n",
    "\n",
    "\n",
    "################# f2 ############################\n",
    "f(x)=100*(x[2]-x[1]^2)^2+(1-x[1])^2\n",
    "gradf(x)=[-400*x[1]*(x[2]-x[1]^2)-2*(1-x[1]) ; 200*(x[2]-x[1]^2)]\n",
    "hessf(x)=[-400*(x[2]-3*x[1]^2)+2  -400*x[1];-400*x[1]  200]\n",
    "x0 = [1; 0]\n",
    "x1 = [sqrt(3)/2; sqrt(3)/2]\n",
    "options = []\n",
    "contrainte(x) =  (x[1]^2) + (x[2]^2) -1.5\n",
    "grad_contrainte(x) = [2*x[1] ;2*x[2]]\n",
    "hess_contrainte(x) = [2 0;0 2]\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"newton\",f,contrainte,gradf,hessf,grad_contrainte,hess_contrainte,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = Newton\",\"f2\",x0,x_min,f_min,flag,[],nb_iters)\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"gct\",f,contrainte,gradf,hessf,grad_contrainte,hess_contrainte,x0,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = GCT\",\"f2\",x0,x_min,f_min,flag,[],nb_iters)\n",
    "\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"newton\",f,contrainte,gradf,hessf,grad_contrainte,hess_contrainte,x1,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = Newton\",\"f2\",x1,x_min,f_min,flag,[],nb_iters)\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"gct\",f,contrainte,gradf,hessf,grad_contrainte,hess_contrainte,x1,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = GCT\",\"f2\",x1,x_min,f_min,flag,[],nb_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation\n",
    " 1.Commenter les résultats obtenus, en étudiant notamment les valeurs de $\\lambda_k$ et $\\mu_k$.\n",
    " \n",
    " 2.Étudier l'influence du paramètre $\\tau$ dans la performance de l'algorithme.\n",
    " \n",
    " 3.**Supplémentaire** : \n",
    "      Que proposez-vous comme méthode pour la résolution des problèmes avec\n",
    "      des contraintes à la fois d'égalité et d'inégalité ? Implémenter (si le temps le permet)\n",
    "      ce nouvel algorithme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réponses\n",
    "\n",
    "1- PLus la valeur absolue de $\\lambda_0$ est petite, plus le nombre d'itération diminue et la précision augmente.\n",
    "Plus la valeur de $\\mu_0$ est grande, plus le nombre d'itération diminue et la précision augmente.\n",
    "\n",
    "2- Plus la valeur de $\\tau$ augmente, plus le nombre d'itération diminue et la précision augmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mRésultats de : Lagrangien avec algo = GCT appliqué à f2 au point initial [0.5, 1.25, 1.0]:\u001b[22m\u001b[39m\n",
      "  * xsol = [0.500000056199409, 1.2499999719002954, 0.5000000561994092]\n",
      "  * f(xsol) = 2.249999494205347\n",
      "  * nb_iters = 1\n",
      "  * flag = 0\n",
      "  * sol_exacte : Any[]\n"
     ]
    }
   ],
   "source": [
    "include(\"Lagrangien_Augmente.jl\")\n",
    "\n",
    "using LinearAlgebra\n",
    "\n",
    "# Fonction f1\n",
    "# -----------\n",
    "f1(x) =  2*(x[1]+x[2]+x[3] - 3)^2 +(x[1]-x[2])^2 + (x[2]-x[3])^2\n",
    "# le gradient de la fonction f1\n",
    "gradf1(x) = [4*(x[1]+x[2]+x[3] - 3)+2*(x[1]-x[2]);4*(x[1]+x[2]+x[3] - 3)-2*(x[1]-x[2])+2*(x[2]-x[3]);4*(x[1]+x[2]+x[3] - 3)-2*(x[2]-x[3])]\n",
    "# la hessienne de la fonction f1\n",
    "hessf1(x) = [6 2 4;2 8 2; 4 2 6]\n",
    "contrainte1(x) = x[1]+x[3]-1\n",
    "grad_contrainte1(x) = [1;0;1]\n",
    "hess_contrainte1(x) = [0 0 0; 0 0 0; 0 0 0]\n",
    "x0 = [0;1;1]\n",
    "x1 = [0.5;1.25;1]\n",
    "\n",
    "options = [ 1e-8, 1e-5, 1000, 2.0, 10000, 10]\n",
    "x_min,f_min,flag,nb_iters = Lagrangien_Augmente(\"gct\",f1,contrainte1,gradf1,hessf1,grad_contrainte1,hess_contrainte1,x1,options)\n",
    "my_afficher_resultats(\"Lagrangien avec algo = GCT\",\"f2\",x1,x_min,f_min,flag,[],nb_iters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
